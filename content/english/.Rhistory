legend("topleft", legend=c("prior", "posterior"), col=c(2,4), lty=c(2,1), lwd=2)
mu0 <- 100
s20 <- 0.8
s2<- 0.025 ## "true" variance
mp<-mu.post(Ybar=m, mu0=mu0, sig20=s20, sig2=s2, n=n)
tp<-tau.post(tau=1/s2, tau0=1/s20, n=n)
x<-seq(1.3,2.3, length=1000)
hist(Y,breaks=10,xlab="Wing Length (mm)", xlim=c(1.3, 2.3),
freq=FALSE, ylim=c(0,8))
lines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior
lines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior
legend("topleft", legend=c("prior", "posterior"), col=c(2,4), lty=c(2,1), lwd=2)
mu0 <- 2.5
s20 <- 0.1
s2<- 0.025 ## "true" variance
mp<-mu.post(Ybar=m, mu0=mu0, sig20=s20, sig2=s2, n=n)
tp<-tau.post(tau=1/s2, tau0=1/s20, n=n)
x<-seq(1.3,2.3, length=1000)
hist(Y,breaks=10,xlab="Wing Length (mm)", xlim=c(1.3, 2.3),
freq=FALSE, ylim=c(0,8))
lines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior
lines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior
legend("topleft", legend=c("prior", "posterior"), col=c(2,4), lty=c(2,1), lwd=2)
mu0 <- 2.5
s20 <- 0.01
s2<- 0.025 ## "true" variance
mp<-mu.post(Ybar=m, mu0=mu0, sig20=s20, sig2=s2, n=n)
tp<-tau.post(tau=1/s2, tau0=1/s20, n=n)
x<-seq(1.3,2.3, length=1000)
hist(Y,breaks=10,xlab="Wing Length (mm)", xlim=c(1.3, 2.3),
freq=FALSE, ylim=c(0,8))
lines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior
lines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior
legend("topleft", legend=c("prior", "posterior"), col=c(2,4), lty=c(2,1), lwd=2)
mu0 <- 2.5
s20 <- 0.001
s2<- 0.025 ## "true" variance
mp<-mu.post(Ybar=m, mu0=mu0, sig20=s20, sig2=s2, n=n)
tp<-tau.post(tau=1/s2, tau0=1/s20, n=n)
x<-seq(1.3,2.3, length=1000)
hist(Y,breaks=10,xlab="Wing Length (mm)", xlim=c(1.3, 2.3),
freq=FALSE, ylim=c(0,8))
lines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior
lines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior
legend("topleft", legend=c("prior", "posterior"), col=c(2,4), lty=c(2,1), lwd=2)
mu0 <- 0
s20 <- 0.1
s2<- 0.025 ## "true" variance
mp<-mu.post(Ybar=m, mu0=mu0, sig20=s20, sig2=s2, n=n)
tp<-tau.post(tau=1/s2, tau0=1/s20, n=n)
x<-seq(1.3,2.3, length=1000)
hist(Y,breaks=10,xlab="Wing Length (mm)", xlim=c(1.3, 2.3),
freq=FALSE, ylim=c(0,8))
lines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior
lines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior
legend("topleft", legend=c("prior", "posterior"), col=c(2,4), lty=c(2,1), lwd=2)
mu0 <- 0
s20 <- 0.8
s2<- 0.025 ## "true" variance
mp<-mu.post(Ybar=m, mu0=mu0, sig20=s20, sig2=s2, n=n)
tp<-tau.post(tau=1/s2, tau0=1/s20, n=n)
x<-seq(1.3,2.3, length=1000)
hist(Y,breaks=10,xlab="Wing Length (mm)", xlim=c(1.3, 2.3),
freq=FALSE, ylim=c(0,8))
lines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior
lines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior
legend("topleft", legend=c("prior", "posterior"), col=c(2,4), lty=c(2,1), lwd=2)
mu0 <- 1.9
s20 <- 0.8
s2<- 0.025 ## "true" variance
mp<-mu.post(Ybar=m, mu0=mu0, sig20=s20, sig2=s2, n=n)
tp<-tau.post(tau=1/s2, tau0=1/s20, n=n)
x<-seq(1.3,2.3, length=1000)
hist(Y,breaks=10,xlab="Wing Length (mm)", xlim=c(1.3, 2.3),
freq=FALSE, ylim=c(0,8))
lines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior
lines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior
legend("topleft", legend=c("prior", "posterior"), col=c(2,4), lty=c(2,1), lwd=2)
knitr::opts_chunk$set(echo = TRUE)
# Load libraries
require(rjags) # does the fitting
require(coda) # makes diagnostic plots
require(R2jags) # fitting
require(MCMCvis)
require(IDPmisc) # makes nice colored pairs plots to look at joint posteriors
##require(mcmcplots) # another option for diagnostic plots, currently unused
install.packages(rjags)
install.packages("rjags")
install.packages("rjags")
# Load libraries
require(rjags) # does the fitting
require(coda) # makes diagnostic plots
require(R2jags) # fitting
require(MCMCvis)
require(IDPmisc) # makes nice colored pairs plots to look at joint posteriors
##require(mcmcplots) # another option for diagnostic plots, currently unused
install.packages("R2jags")
install.packages("MCMCvis")
# Load libraries
require(rjags) # does the fitting
require(coda) # makes diagnostic plots
require(R2jags) # fitting
require(MCMCvis)
require(IDPmisc) # makes nice colored pairs plots to look at joint posteriors
install.package("IDPmsic")
install.packages("IDPmsic")
install.packages("languageserver")
install.packages("languageserver")
# Load data
WL.data <- read.csv("/home/joeh/Documents/R/Bayesian/MidgeWingLength.csv")
Y <- WL.data$WingLength
n <- length(Y)
hist(Y,breaks=10,xlab="Wing Length (mm)")
#Weâ€™ll also need summary statistics for the data that we calculated last time:
m<-sum(Y)/n
s2<-sum((Y-m)^2)/(n-1)
tau.post<-function(tau, tau0, n){n*tau + tau0}
mu.post<-function(Ybar, mu0, sig20, sig2, n){
weight<-sig2+n*sig20
return(n*sig20*Ybar/weight + sig2*mu0/weight)
}
mu0 <- 1.9
s20 <- 0.8
s2<- 0.025 ## "true" variance
mp<-mu.post(Ybar=m, mu0=mu0, sig20=s20, sig2=s2, n=n)
tp<-tau.post(tau=1/s2, tau0=1/s20, n=n)
x<-seq(1.3,2.3, length=1000)
hist(Y,breaks=10,xlab="Wing Length (mm)", xlim=c(1.3, 2.3),
freq=FALSE, ylim=c(0,8))
lines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior
lines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior
legend("topleft", legend=c("prior", "posterior"), col=c(2,4), lty=c(2,1), lwd=2)
model1 <- "model{
## Likelihood
for(i in 1:n){
Y[i] ~ dnorm(mu,tau)
}
## Prior for mu
mu        ~ dnorm(mu0,tau0)
} ## close model
"
Now we will create the JAGS model
model1 <- "model{
## Likelihood
for(i in 1:n){
Y[i] ~ dnorm(mu,tau)
}
## Prior for mu
mu        ~ dnorm(mu0,tau0)
} ## close model
"
#Now we will create the JAGS model
model <- jags.model(textConnection(model1),
n.chains = 1, ## usually do more
data = list(Y=Y,n=n, ## data
mu0=mu0, tau0=1/s20, ## hyperparams
tau = 1/s2 ## known precision
),
inits=list(mu=3) ## setting an starting val
)
samp <- coda.samples(model,
variable.names=c("mu"),
n.iter=1000, progress.bar="none")
plot(samp)
update(model, 10000, progress.bar="none") # Burnin for 10000 samples
samp <- coda.samples(model,
variable.names=c("mu"),
n.iter=20000, progress.bar="none")
plot(samp)
summary(samp)
x<-seq(1.3,2.3, length=1000)
hist(samp[[1]], xlab="mu", xlim=c(1.3, 2.3),
freq=FALSE, ylim=c(0,8), main ="posterior samples")
lines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior
lines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior
legend("topleft", legend=c("prior", "analytic posterior"), col=c(2,4), lty=c(2,1), lwd=2)
model2 <- "model{
# Likelihood
for(i in 1:n){
Y[i] ~ dnorm(mu,tau) T(0,) ## truncates at 0
}
# Prior for mu
mu    ~ dnorm(mu0,tau0)
# Prior for the precision
tau   ~ dgamma(a, b)
# Compute the variance
s2       <- 1/tau
}"
## hyperparams for tau
a   <- 0.01
b   <- 0.01
m2 <- jags.model(textConnection(model2),
n.chains = 1,
data = list(Y=Y, n=n,
mu0=mu0, tau0=1/s20, ## mu hyperparams
a=a, b=b ## tau hyperparams
),
inits=list(mu=3, tau=10) ## starting vals
)
## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 9
##    Unobserved stochastic nodes: 2
##    Total graph size: 19
##
## Initializing model
samp <- coda.samples(m2,
variable.names=c("mu","s2"),
n.iter=1000, progress.bar="none")
plot(samp)
summary(samp)
##
## Iterations = 1001:2000
## Thinning interval = 1
## Number of chains = 1
## Sample size per chain = 1000
##
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
##
##       Mean      SD  Naive SE Time-series SE
## mu 1.80667 0.05345 0.0016902      0.0021671
## s2 0.02616 0.01773 0.0005606      0.0009147
##
## 2. Quantiles for each variable:
##
##        2.5%     25%     50%     75%   97.5%
## mu 1.703177 1.77215 1.80465 1.83952 1.91437
## s2 0.008737 0.01515 0.02124 0.03095 0.07357
par(mfrow=c(1,2), bty="n")
hist(samp[[1]][,1], xlab="samples of mu", main="mu", freq=FALSE)
lines(x, dnorm(x, mean=mu0, sd=sqrt(s20)),
col=2, lty=2, lwd=2) ## prior
x2<-seq(0, 200, length=1000)
hist(1/samp[[1]][,2], xlab="samples of tau", main="tau", freq=FALSE)
lines(x2, dgamma(x2, shape = a, rate = b),
col=2, lty=2, lwd=2) ## prior
plot(as.numeric(samp[[1]][,1]), samp[[1]][,2],
xlab="mu", ylab="s2")
set.seed(1234)
Aaeg.data <- read.csv("../data/AeaegyptiTraitData.csv")
set.seed(1234)
Aaeg.data <- read.csv("/home/joeh/Documents/R/Bayesian/AeaegyptiTraitData.csv")
head(Aaeg.data)
mu.data <- subset(Aaeg.data, trait.name == "mu")
lf.data <- subset(Aaeg.data, trait.name == "1/mu")
par(mfrow=c(1,2), bty="l")
plot(trait ~ T, data = mu.data, ylab="mu")
plot(trait ~ T, data = lf.data, ylab="1/mu")
mu.data.inv <- mu.data # make a copy of the mu data
mu.data.inv$trait <- 1/mu.data$trait # take the inverse of the trait values to convert mu to lifespan
lf.data.comb <- rbind(mu.data.inv, lf.data) # combine both lifespan data sets together
plot(trait ~ T, data = lf.data.comb, ylab="1/mu")
model{
model{
model <- model{
sink("external.txt")
model{
sink("external.txt")
"model{
## Priors
cf.q ~ dunif(0, 1)
cf.T0 ~ dunif(0, 24)
cf.Tm ~ dunif(25, 45)
cf.sigma ~ dunif(0, 1000)
cf.tau <- 1 / (cf.sigma * cf.sigma)
## Likelihood
for(i in 1:N.obs){
trait.mu[i] <- -1 * cf.q * (temp[i] - cf.T0) * (temp[i] - cf.Tm) * (cf.Tm > temp[i]) * (cf.T0 < temp[i])
trait[i] ~ dnorm(trait.mu[i], cf.tau)
}
## Derived Quantities and Predictions
for(i in 1:N.Temp.xs){
z.trait.mu.pred[i] <- -1 * cf.q * (Temp.xs[i] - cf.T0) * (Temp.xs[i] - cf.Tm) * (cf.Tm > Temp.xs[i]) * (cf.T0 < Temp.xs[i])
}
} # close model"
sink()
# Parameters to Estimate
parameters <- c("cf.q", "cf.T0", "cf.Tm","cf.sigma", "z.trait.mu.pred")
# Initial values for the parameters
inits<-function(){list(
cf.q = 0.01,
cf.Tm = 35,
cf.T0 = 5,
cf.sigma = rlnorm(1))}
# MCMC Settings: number of posterior dist elements = [(ni - nb) / nt ] * nc
ni <- 25000 # number of iterations in each chain
nb <- 5000 # number of 'burn in' iterations to discard
nt <- 8 # thinning rate - jags saves every nt iterations in each chain
nc <- 3 # number of chains
# Temperature sequence for derived quantity calculations
Temp.xs <- seq(0, 45, 0.2)
N.Temp.xs <-length(Temp.xs)
### Fitting the trait thermal response; Pull out data columns as vectors
data <- lf.data.comb # this lets us reuse the same generic code: we only change this first line
trait <- data$trait
N.obs <- length(trait)
temp <- data$T
# Bundle all data in a list for JAGS
jag.data<-list(trait = trait, N.obs = N.obs, temp = temp, Temp.xs = Temp.xs, N.Temp.xs = N.Temp.xs)
lf.fit <- jags(data=jag.data, inits=inits, parameters.to.save=parameters,
model.file="/home/joeh/Documents/R/Bayesian/external.txt", n.thin=nt, n.chains=nc, n.burnin=nb,
n.iter=ni, DIC=T, working.directory=getwd())
lf.fit <- jags(data=jag.data, inits=inits, parameters.to.save=parameters,
model.file="/home/joeh/Documents/R/Bayesian/external.txt", n.thin=nt, n.chains=nc, n.burnin=nb,
n.iter=ni, DIC=T)
model3 <- "model{
## Priors
cf.q ~ dunif(0, 1)
cf.T0 ~ dunif(0, 24)
cf.Tm ~ dunif(25, 45)
cf.sigma ~ dunif(0, 1000)
cf.tau <- 1 / (cf.sigma * cf.sigma)
## Likelihood
for(i in 1:N.obs){
trait.mu[i] <- -1 * cf.q * (temp[i] - cf.T0) * (temp[i] - cf.Tm) * (cf.Tm > temp[i]) * (cf.T0 < temp[i])
trait[i] ~ dnorm(trait.mu[i], cf.tau)
}
## Derived Quantities and Predictions
for(i in 1:N.Temp.xs){
z.trait.mu.pred[i] <- -1 * cf.q * (Temp.xs[i] - cf.T0) * (Temp.xs[i] - cf.Tm) * (cf.Tm > Temp.xs[i]) * (cf.T0 < Temp.xs[i])
}
} # close model"
# Parameters to Estimate
parameters <- c("cf.q", "cf.T0", "cf.Tm","cf.sigma", "z.trait.mu.pred")
# Initial values for the parameters
inits<-function(){list(
cf.q = 0.01,
cf.Tm = 35,
cf.T0 = 5,
cf.sigma = rlnorm(1))}
# MCMC Settings: number of posterior dist elements = [(ni - nb) / nt ] * nc
ni <- 25000 # number of iterations in each chain
nb <- 5000 # number of 'burn in' iterations to discard
nt <- 8 # thinning rate - jags saves every nt iterations in each chain
nc <- 3 # number of chains
# Temperature sequence for derived quantity calculations
Temp.xs <- seq(0, 45, 0.2)
N.Temp.xs <-length(Temp.xs)
### Fitting the trait thermal response; Pull out data columns as vectors
data <- lf.data.comb # this lets us reuse the same generic code: we only change this first line
trait <- data$trait
N.obs <- length(trait)
temp <- data$T
# Bundle all data in a list for JAGS
jag.data<-list(trait = trait, N.obs = N.obs, temp = temp, Temp.xs = Temp.xs, N.Temp.xs = N.Temp.xs)
lf.fit <- jags(data=jag.data, inits=inits, parameters.to.save=parameters,
model = model3, n.thin=nt, n.chains=nc, n.burnin=nb,
n.iter=ni, DIC=T)
# Derived Quantities and Predictions
model3 <- "model{
cf.q ~ dunif(0, 1)
cf.T0 ~ dunif(0, 24)
cf.Tm ~ dunif(25, 45)
cf.sigma ~ dunif(0, 1000)
cf.tau <- 1 / (cf.sigma * cf.sigma)
for(i in 1:N.obs){
trait.mu[i] <- -1 * cf.q * (temp[i] - cf.T0) * (temp[i] - cf.Tm) * (cf.Tm > temp[i]) * (cf.T0 < temp[i])
trait[i] ~ dnorm(trait.mu[i], cf.tau)
}
# Derived Quantities and Predictions
for(i in 1:N.Temp.xs){
z.trait.mu.pred[i] <- -1 * cf.q * (Temp.xs[i] - cf.T0) * (Temp.xs[i] - cf.Tm) * (cf.Tm > Temp.xs[i]) * (cf.T0 < Temp.xs[i])
}
}"
# Parameters to Estimate
parameters <- c("cf.q", "cf.T0", "cf.Tm","cf.sigma", "z.trait.mu.pred")
# Initial values for the parameters
inits<-function(){list(
cf.q = 0.01,
cf.Tm = 35,
cf.T0 = 5,
cf.sigma = rlnorm(1))}
# MCMC Settings: number of posterior dist elements = [(ni - nb) / nt ] * nc
ni <- 25000 # number of iterations in each chain
nb <- 5000 # number of 'burn in' iterations to discard
nt <- 8 # thinning rate - jags saves every nt iterations in each chain
nc <- 3 # number of chains
# Temperature sequence for derived quantity calculations
Temp.xs <- seq(0, 45, 0.2)
N.Temp.xs <-length(Temp.xs)
### Fitting the trait thermal response; Pull out data columns as vectors
data <- lf.data.comb # this lets us reuse the same generic code: we only change this first line
trait <- data$trait
N.obs <- length(trait)
temp <- data$T
# Bundle all data in a list for JAGS
jag.data<-list(trait = trait, N.obs = N.obs, temp = temp, Temp.xs = Temp.xs, N.Temp.xs = N.Temp.xs)
lf.fit <- jags(data=jag.data, inits=inits, parameters.to.save=parameters,
model = model3, n.thin=nt, n.chains=nc, n.burnin=nb,
n.iter=ni, DIC=T)
lf.fit <- jags.model(textconnection(model3), data=jag.data, inits=inits, parameters.to.save=parameters, n.thin=nt, n.chains=nc, n.burnin=nb, n.iter=ni, DIC=T)
lf.fit <- jags(data=jag.data, inits=inits, parameters.to.save=parameters,
model = model3, n.thin=nt, n.chains=nc, n.burnin=nb,
n.iter=ni, DIC=T)
?jags
lf.fit <- jags(data=jag.data, inits=inits, parameters.to.save=parameters,
model.file = "/home/joeh/Documents/R/Bayesian/external.txt", n.thin=nt, n.chains=nc, n.burnin=nb,
n.iter=ni, DIC=T)
lf.fit <- jags(data=jag.data, inits=inits, parameters.to.save=parameters,
model.file = "/home/joeh/Documents/R/Bayesian/external.txt", n.thin=nt, n.chains=nc, n.burnin=nb,
n.iter=ni, DIC=T)
# Parameters to Estimate
parameters <- c("cf.q", "cf.T0", "cf.Tm","cf.sigma", "z.trait.mu.pred")
# Initial values for the parameters
inits<-function(){list(
cf.q = 0.01,
cf.Tm = 35,
cf.T0 = 5,
cf.sigma = rlnorm(1))}
# MCMC Settings: number of posterior dist elements = [(ni - nb) / nt ] * nc
ni <- 25000 # number of iterations in each chain
nb <- 5000 # number of 'burn in' iterations to discard
nt <- 8 # thinning rate - jags saves every nt iterations in each chain
nc <- 3 # number of chains
# Temperature sequence for derived quantity calculations
Temp.xs <- seq(0, 45, 0.2)
N.Temp.xs <-length(Temp.xs)
### Fitting the trait thermal response; Pull out data columns as vectors
data <- lf.data.comb # this lets us reuse the same generic code: we only change this first line
trait <- data$trait
N.obs <- length(trait)
temp <- data$T
# Bundle all data in a list for JAGS
jag.data<-list(trait = trait, N.obs = N.obs, temp = temp, Temp.xs = Temp.xs, N.Temp.xs = N.Temp.xs)
lf.fit <- jags(data=jag.data, inits=inits, parameters.to.save=parameters,
model.file = "/home/joeh/Documents/R/Bayesian/external.txt", n.thin=nt, n.chains=nc, n.burnin=nb,
n.iter=ni, DIC=T)
lf.fit <- jags(data=jag.data, inits=inits, parameters.to.save=parameters,
model.file = "/home/joeh/Documents/R/Bayesian/external.txt", n.thin=nt, n.chains=nc, n.burnin=nb,
n.iter=ni, DIC=T)
lf.fit.mcmc <- as.mcmc(lf.fit) ## makes and "mcmc" object
lf.fit$BUGSoutput$summary[1:5,]
lf.fit$BUGSoutput$summary[1:5,]
print(lf.fit$BUGSoutput$summary[1:5,])
lf.fit$BUGSoutput$summary
a <- lf.fit$BUGSoutput$summary
a[1:5,]
View(a)
head(lf.fit$BUGSoutput$summary)
View(lf.fit$BUGSoutput$summary)
## plot(lf.fit.mcmc[,c(1,3,4)]) ## default coda plot
MCMCtrace(lf.fit.mcmc,
params=c("cf.q", "cf.Tm", "cf.T0"),
pdf=FALSE) ## from the MCMCvis package
s1<-as.data.frame(lf.fit.mcmc[[1]])
par(mfrow=c(3,1))
for(i in c(1,3,4)) acf(s1[,i], lag.max=20)
priors<-matrix(NA, nrow=10000, ncol=3) # 3 params, 1 each
priors[,1]<- runif(10000, min=0, max=1) ## q
priors[,2]<- runif(10000, min=25, max=45) ## TM
priors[,3]<- runif(10000, min=0, max=24) ## T0
MCMCtrace(lf.fit.mcmc,
params=c("cf.q", "cf.Tm", "cf.T0"),
priors=priors,
post_zm = FALSE,
type= "density",
pdf=FALSE) ## from the MCMCvis package
ipairs(s1[,c(1,3,4)], ztransf = function(x){x[x<1] <- 1; log2(x)})
install.packages("IDPmisc")
library(IDPmisc)
ipairs(s1[,c(1,3,4)], ztransf = function(x){x[x<1] <- 1; log2(x)})
plot(trait ~ T, xlim = c(0, 45), ylim = c(0,42), data = lf.data.comb,
ylab = "Lifespan for Ae. aegypti", xlab = "Temperature")
lines(lf.fit$BUGSoutput$summary[6:(6 + N.Temp.xs - 1), "2.5%"] ~ Temp.xs,
lty = 2, col=2, lwd=2)
lines(lf.fit$BUGSoutput$summary[6:(6 + N.Temp.xs - 1), "97.5%"] ~ Temp.xs,
lty = 2, col=2, lwd=2)
lines(lf.fit$BUGSoutput$summary[6:(6 + N.Temp.xs - 1), "mean"] ~ Temp.xs)
Temp.xs[which.max(as.vector(lf.fit$BUGSoutput$summary[6:(6 + N.Temp.xs - 1), "mean"]))]
lf.grad <- lf.fit$BUGSoutput$sims.list$z.trait.mu.pred
dim(lf.grad) # A matrix with 7500 iterations of the MCMC chains at 226 temperatures
install.packages("tidyverse")
install.packages("systemfonts")
install.packages("systemfonts")
install.packages("curl")
install.packages("curl")
install.packages("textshaping")
install.packages("textshaping")
install.packages("rvest")
install.packages("tidyverse")
install.packages("tidyverse")
getwd()
setwd("/home/joeh/Documents/chess_project/chess_data/content/english")
getwd()
ls()
knitr
install.packages("DBI")
install.packages("DBI")
install.packages("dlookr")
install.packages("httr")
install.packages("RPostgres")
install.packages("RPostgres")
knitr
knitr::knit("_index.Rmd")
install.packages("tidyverse")
install.packages("devtools")
install.packages("pkgdown")
install.packages("pkgdown")
install.packages("pkgdown")
install.packages("devtools")
install.packages("tidyverse")
install.packages("broom")
insatl.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("broom")
install.packages("tidyr")
install.packages("tidyverse")
knitr::knit("_index.Rmd")
